{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af9e07f-4aed-49ff-92dc-154973873f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from cyvcf2 import VCF\n",
    "from pyfaidx import Fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426ee53a-9254-4b40-8eb5-d238eae7524b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers.trainer_callback import EarlyStoppingCallback, TrainerCallback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7026eb-68ee-4f61-95fe-f6ae16e697fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3342cf6-773b-4650-af81-0772cdbe75a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './clinvar_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e9169b-cdc2-4831-8e83-4c85201b12ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REF_DIR = os.path.join(DATA_PATH,'refs/GRCh38_gencode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fc73d0-f16c-4e29-b095-d9eefe5373b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(DATA_PATH,\"processed_data\")\n",
    "OUT_DIR = os.path.join(DATA_PATH,'clinvar_outs')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5142931-466d-4cef-9dc8-609f1ff87427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLINVAR_VCF_PATH = os.path.join(DATA_PATH, \"clinvar_GRCh38.vcf.gz\")\n",
    "GENCODE_FASTA_GZ = os.path.join(REF_DIR,\"GRCh38.primary_assembly.genome.fa.gz\")\n",
    "GENCODE_FASTA = os.path.join(REF_DIR,\"GRCh38.primary_assembly.genome.fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420c6c5-1abd-45df-b41e-586468b21f9e",
   "metadata": {},
   "source": [
    "# Model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6526fa6b-b581-4e74-b476-7f4c7574623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task / model\n",
    "MODEL_NAME   = \"InstaDeepAI/nucleotide-transformer-500m-human-ref\"\n",
    "KMER         = 6\n",
    "MAX_TOKENS   = 1000                 # 999 k-mers + CLS\n",
    "SEQ_LEN      = 1004                 # → 999 k-mers for k=6 (L - k + 1)\n",
    "# FLANK        = (SEQ_LEN - 1) // 2   # \n",
    "LEFT_FLANK   = SEQ_LEN // 2         # 501 on each side when L=1004 \n",
    "RIGHT_FLANK  = SEQ_LEN - LEFT_FLANK - 1 # 502 bases to the left of SNV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae95b0d-032b-4ebb-9e30-fe353a226640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "POS_LABEL    = \"pathogenic\"\n",
    "NEG_LABEL    = \"benign\"\n",
    "USE_LABELS   = [NEG_LABEL, POS_LABEL]  # label mapping: benign->0, pathogenic->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f1e920-e33b-447a-bb11-7206ed61acb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 5\n",
    "BATCH_SIZE   = 32\n",
    "LR           = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45acdcdc-918e-4e36-8ec2-711764061938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_BF16 = torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8\n",
    "USE_FP16 = (not USE_BF16) and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be71db9f-cd90-4fcf-905d-d9a267cd419d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cfa62-aa5f-4fa2-b71d-3326fcfc4d0f",
   "metadata": {},
   "source": [
    "# Parse clinvar\n",
    "### Benign/Pathogenic (+ optional Uncertain sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5641e932-f237-4f4a-b15b-45182c3b478a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vcf = VCF(CLINVAR_VCF_PATH)\n",
    "\n",
    "# clnsig = var.INFO.get(\"CLNSIG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e282b88-0e6e-4c31-85f9-4a18eae9a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_clinvar(vcf_path: str, sample_uncertain_k: int = 100_000):\n",
    "    \"\"\"Parse ClinVar VCF and bucket SNVs by clinical significance.\n",
    "       keep *Pathogenic* and *Benign* **only**.\n",
    "       Exclude Likely_* (both likely_pathogenic/likely_benign), Uncertain, Conflicting, and mixed cases.\n",
    "    \"\"\"\n",
    "    vcf = VCF(vcf_path)\n",
    "    benign, pathogenic, uncertain = [], [], []\n",
    "\n",
    "    def normalize_sig(val: str) -> list[str]:\n",
    "        # split on common separators and normalize\n",
    "        toks = re.split(r\"[\\|;,/]+\", val)\n",
    "        out = []\n",
    "        for t in toks:\n",
    "            t = t.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            if t:\n",
    "                out.append(t)\n",
    "        return out\n",
    "\n",
    "    for var in tqdm(vcf, desc=\"Parsing ClinVar VCF (strict)\"):\n",
    "        # SNVs only\n",
    "        if len(var.REF) != 1 or var.ALT is None or len(var.ALT) != 1 or any(len(a) != 1 for a in var.ALT):\n",
    "            continue\n",
    "        clnsig = var.INFO.get(\"CLNSIG\")\n",
    "        if clnsig is None:\n",
    "            continue\n",
    "        toks = set(normalize_sig(str(clnsig)))  \n",
    "\n",
    "        # core flags\n",
    "        has_path = \"pathogenic\" in toks\n",
    "        has_ben  = \"benign\" in toks\n",
    "        has_lpath = \"likely_pathogenic\" in toks\n",
    "        has_lben  = \"likely_benign\" in toks\n",
    "        has_unc   = \"uncertain_significance\" in toks\n",
    "        has_conf  = \"conflicting_interpretations_of_pathogenicity\" in toks\n",
    "\n",
    "        # strict filters — accept only pure Pathogenic or pure Benign\n",
    "        if has_conf or has_unc or has_lpath or has_lben:\n",
    "            continue  # strict mode drops these entirely\n",
    "\n",
    "        # Mixed strict classes also dropped\n",
    "        if has_path and has_ben:\n",
    "            continue\n",
    "\n",
    "        if has_path and not has_ben:\n",
    "            pathogenic.append(var)\n",
    "            continue\n",
    "        if has_ben and not has_path:\n",
    "            benign.append(var)\n",
    "            continue\n",
    "        # else: nothing to do (drop)\n",
    "\n",
    "    print(f\"Collected (STRICT): benign={len(benign)}, pathogenic={len(pathogenic)} | dropped all other labels\")\n",
    "    # uncertain list kept empty in strict mode; return signature unchanged\n",
    "    return benign, pathogenic, uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3512fafd-6d3b-4a69-989a-12174fb95fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing ClinVar VCF (strict): 3683953it [00:31, 116580.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected (STRICT): benign=181304, pathogenic=81598 | dropped all other labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benign_vars, pathogenic_vars, uncertain_vars = parse_clinvar(CLINVAR_VCF_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed74aa-2172-4c5c-b9ac-1ad51e683a84",
   "metadata": {},
   "source": [
    "#  Reference genome (GENCODE) & contig name harmonization\n",
    "\n",
    "### ClinVar GRCh38 VCF may use **RefSeq** contig names like `NC_000001.11`, whereas **GENCODE** uses Ensembl-style names `1..22, X, Y, MT`.\n",
    "### The function below generates a set of candidate contig names to try when fetching sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c12f2aa6-41f2-4174-aeb2-650482ddea24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_genome = Fasta(GENCODE_FASTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d270b561-6b87-4738-b385-c8a2fb7b7263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fasta(\"./clinvar_data/refs/GRCh38_gencode/GRCh38.primary_assembly.genome.fa\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75c2e1ad-9fc4-4b80-a607-f81ae6595383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref_genome.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bbbdee5-73a8-46d1-aa46-9eff15011825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vcf.seqnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fb2c161-672d-42c2-b32a-f17a69314678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map RefSeq NC_* accessions to Ensembl-like chrom labels when possible\n",
    "NC_TO_ENSEMBL_SPECIAL = {\n",
    "    23: \"X\",\n",
    "    24: \"Y\",\n",
    "    12920: \"MT\",  # NC_012920.1 → mitochondrion\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02c49da2-4842-4439-a9ca-85dbc016c78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contig_candidates(chrom: str) -> List[str]:\n",
    "    \"\"\"Return plausible contig name candidates across naming conventions.\n",
    "    - Accepts inputs like 'chr1', '1', 'NC_000001.11', 'chrX', 'X', 'MT', 'chrM'\n",
    "    - Returns unique candidates in priority order.\n",
    "    \"\"\"\n",
    "    cands = []\n",
    "    # As-is\n",
    "    cands.append(chrom)\n",
    "\n",
    "    # Strip/add 'chr'\n",
    "    if chrom.startswith(\"chr\"):\n",
    "        cands.append(chrom[3:])\n",
    "    else:\n",
    "        cands.append(\"chr\" + chrom)\n",
    "\n",
    "    # Map NC_0000XX.yy → 1..22/X/Y/MT\n",
    "    m = re.match(r\"NC_(\\d{6})\\.(\\d+)\", chrom)\n",
    "    if m:\n",
    "        num = int(m.group(1))\n",
    "        if 1 <= num <= 22:\n",
    "            cands += [str(num), f\"chr{num}\"]\n",
    "        elif num in NC_TO_ENSEMBL_SPECIAL:\n",
    "            val = NC_TO_ENSEMBL_SPECIAL[num]\n",
    "            cands += [val, f\"chr{val}\"]\n",
    "\n",
    "    # Support chrM/chrMT → MT\n",
    "    if chrom in (\"chrM\", \"chrMT\"):\n",
    "        cands += [\"MT\"]\n",
    "\n",
    "    # Deduplicate preserving order\n",
    "    out = []\n",
    "    for x in cands:\n",
    "        if x not in out:\n",
    "            out.append(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040b05f-7225-47fc-943c-39574f9e736b",
   "metadata": {},
   "source": [
    "# Build paired windows (ref/alt) centered on SNVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c04a5b42-0a39-4b40-b0f3-3fd90b809dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_centered_ref_alt(chrom: str, pos_1based: int, ref: str, alt: str) -> Optional[Tuple[str, str]]:\n",
    "   # Use LEFT_FLANK / RIGHT_FLANK for SEQ_LEN=1004\n",
    "    fasta_contig = None\n",
    "    for name in contig_candidates(chrom):\n",
    "        if name in ref_genome:\n",
    "            fasta_contig = name\n",
    "            break\n",
    "    if fasta_contig is None:\n",
    "        return None\n",
    "\n",
    "    # Skip unresolvable scaffolds early (NT_ / NW_ are not in primary assembly)\n",
    "    if chrom.startswith((\"NT_\", \"NW_\")) and fasta_contig not in ref_genome:  \n",
    "        return None\n",
    "\n",
    "    snv0 = pos_1based - 1\n",
    "    start = snv0 - LEFT_FLANK       \n",
    "    end   = snv0 + RIGHT_FLANK + 1  \n",
    "    if start < 0 or end > len(ref_genome[fasta_contig]):\n",
    "        return None\n",
    "\n",
    "    ref_window = ref_genome[fasta_contig][start:end].seq.upper()\n",
    "    if len(ref_window) != SEQ_LEN:  # exact length check for 1004\n",
    "        return None\n",
    "\n",
    "    center_idx = LEFT_FLANK         #SNV sits here\n",
    "   \n",
    "\n",
    "    alt_window = ref_window[:center_idx] + alt.upper() + ref_window[center_idx + 1:]\n",
    "    return ref_window, alt_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e389ac-0b76-459a-8ace-dab733d24c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variants_to_dataframe(variants, label: str, max_n: Optional[int] = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    it = variants if max_n is None else variants[:max_n]\n",
    "\n",
    "    # debug counters\n",
    "    skipped_no_contig = skipped_bounds = skipped_len = skipped_other = 0  \n",
    "\n",
    "    for v in tqdm(it, desc=f\"Building rows: {label}\"):\n",
    "        chrom, pos, ref, alts = v.CHROM, v.POS, v.REF, v.ALT\n",
    "        if alts is None or len(alts) != 1:\n",
    "            continue\n",
    "        alt = alts[0]\n",
    "\n",
    "        pair = extract_centered_ref_alt(chrom, pos, ref, alt)  \n",
    "        if pair is None:\n",
    "            fasta_contig = next((n for n in contig_candidates(chrom) if n in ref_genome), None)\n",
    "            if fasta_contig is None:\n",
    "                skipped_no_contig += 1  \n",
    "            else:\n",
    "                snv0 = pos - 1\n",
    "                start = snv0 - LEFT_FLANK\n",
    "                end   = snv0 + RIGHT_FLANK + 1\n",
    "                if start < 0 or end > len(ref_genome[fasta_contig]):\n",
    "                    skipped_bounds += 1  \n",
    "                else:\n",
    "                    # could be length or masked mismatch; we already turned off strict central-base\n",
    "                    skipped_len += 1  # closest bucket\n",
    "            continue\n",
    "\n",
    "        ref_seq, alt_seq = pair\n",
    "        if len(ref_seq) != SEQ_LEN or len(alt_seq) != SEQ_LEN:\n",
    "            skipped_len += 1  \n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"chrom\": chrom,\n",
    "            \"pos\": pos,\n",
    "            \"ref\": ref,\n",
    "            \"alt\": alt,\n",
    "            \"label\": label,\n",
    "            \"ref_seq\": ref_seq,\n",
    "            \"alt_seq\": alt_seq,\n",
    "        })\n",
    "\n",
    "    # print debug summary\n",
    "    print(f\"[{label}] kept={len(rows)} \"\n",
    "          f\"| no_contig={skipped_no_contig} bounds={skipped_bounds} len_mismatch={skipped_len} other={skipped_other}\")  \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f3f3542-ea58-4d63-b3f2-622317bf65f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has chr1? True\n",
      "Has chrM? True\n",
      "Example variant: 1 930165 G ['A']\n",
      "Candidates: ['1', 'chr1']\n",
      "Extractable? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####Sanity Test\n",
    "print(\"Has chr1?\", \"chr1\" in ref_genome)     # True\n",
    "print(\"Has chrM?\", \"chrM\" in ref_genome)     # True\n",
    "\n",
    "v = benign_vars[0]\n",
    "print(\"Example variant:\", v.CHROM, v.POS, v.REF, v.ALT)\n",
    "print(\"Candidates:\", contig_candidates(v.CHROM))\n",
    "print(\"Extractable?\", extract_centered_ref_alt(v.CHROM, v.POS, v.REF, v.ALT[0]) is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70e13b89-0fac-4f5b-9ce3-961ed9565c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting benign windows ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building rows: benign: 100%|██████████| 181304/181304 [00:03<00:00, 57969.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[benign] kept=180412 | no_contig=892 bounds=0 len_mismatch=0 other=0\n",
      "Extracting pathogenic windows ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building rows: pathogenic: 100%|██████████| 81598/81598 [00:01<00:00, 53038.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pathogenic] kept=81554 | no_contig=44 bounds=0 len_mismatch=0 other=0\n"
     ]
    }
   ],
   "source": [
    "# Build dataframes\n",
    "print(\"Extracting benign windows ...\")\n",
    "df_benign     = variants_to_dataframe(benign_vars, NEG_LABEL)\n",
    "print(\"Extracting pathogenic windows ...\")\n",
    "df_pathogenic = variants_to_dataframe(pathogenic_vars, POS_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e35530a2-c8b4-42ab-849f-7fcd8987feed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[benign] unresolved contigs = 892 across 2 names\n",
      "  MT: 891\n",
      "  NT_187693.1: 1\n",
      "[pathogenic] unresolved contigs = 44 across 1 names\n",
      "  MT: 44\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def pick_fasta_contig(chrom: str):\n",
    "    for name in contig_candidates(chrom):\n",
    "        if name in ref_genome:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def summarize_unresolved(vars_list, label):\n",
    "    bad = []\n",
    "    for v in vars_list:\n",
    "        if pick_fasta_contig(v.CHROM) is None:\n",
    "            bad.append(v.CHROM)\n",
    "    c = Counter(bad)\n",
    "    print(f\"[{label}] unresolved contigs = {sum(c.values())} across {len(c)} names\")\n",
    "    for name, n in c.most_common(15):\n",
    "        print(f\"  {name}: {n}\")\n",
    "\n",
    "summarize_unresolved(benign_vars, \"benign\")\n",
    "summarize_unresolved(pathogenic_vars, \"pathogenic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b9c4c45-a64f-4ccd-b1b1-5ccbe8d20110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>ref_seq</th>\n",
       "      <th>alt_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>930165</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...</td>\n",
       "      <td>CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>930204</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...</td>\n",
       "      <td>CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>930285</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...</td>\n",
       "      <td>CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>930314</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>benign</td>\n",
       "      <td>CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...</td>\n",
       "      <td>CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>930325</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>benign</td>\n",
       "      <td>GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...</td>\n",
       "      <td>GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom     pos ref alt   label  \\\n",
       "0     1  930165   G   A  benign   \n",
       "1     1  930204   G   A  benign   \n",
       "2     1  930285   G   A  benign   \n",
       "3     1  930314   C   T  benign   \n",
       "4     1  930325   C   T  benign   \n",
       "\n",
       "                                             ref_seq  \\\n",
       "0  CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...   \n",
       "1  CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...   \n",
       "2  CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...   \n",
       "3  CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...   \n",
       "4  GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...   \n",
       "\n",
       "                                             alt_seq  \n",
       "0  CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...  \n",
       "1  CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...  \n",
       "2  CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...  \n",
       "3  CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...  \n",
       "4  GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb62bce3-31f5-4ffb-ade9-a864fb14f5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>ref_seq</th>\n",
       "      <th>alt_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>943995</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>AGTGCGCAGCAGGGACTGGACTGTGCACCCCACCTTTTTTTTTTTT...</td>\n",
       "      <td>AGTGCGCAGCAGGGACTGGACTGTGCACCCCACCTTTTTTTTTTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1014143</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>CCAGCCAAGGTCTCCCAGGGGTGCAGGGAGAGCGGAGCTGCTCAGA...</td>\n",
       "      <td>CCAGCCAAGGTCTCCCAGGGGTGCAGGGAGAGCGGAGCTGCTCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022368</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>TGTGGAAGGCAGGCACCCCAAGCCAGGTGGGCCCCCTTCCCAAATT...</td>\n",
       "      <td>TGTGGAAGGCAGGCACCCCAAGCCAGGTGGGCCCCCTTCCCAAATT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1041582</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>GGCTGGGAGGGGCCTGGGGGGCGGAGCGGGGCGGGAGCGGGGCGGG...</td>\n",
       "      <td>GGCTGGGAGGGGCCTGGGGGGCGGAGCGGGGCGGGAGCGGGGCGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1041975</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>CCCAGACCCCTGTCAGGGCGCCCTCCCTGACCCGAGCCGCAGCTGC...</td>\n",
       "      <td>CCCAGACCCCTGTCAGGGCGCCCTCCCTGACCCGAGCCGCAGCTGC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom      pos ref alt       label  \\\n",
       "0     1   943995   C   T  pathogenic   \n",
       "1     1  1014143   C   T  pathogenic   \n",
       "2     1  1022368   C   A  pathogenic   \n",
       "3     1  1041582   C   T  pathogenic   \n",
       "4     1  1041975   C   A  pathogenic   \n",
       "\n",
       "                                             ref_seq  \\\n",
       "0  AGTGCGCAGCAGGGACTGGACTGTGCACCCCACCTTTTTTTTTTTT...   \n",
       "1  CCAGCCAAGGTCTCCCAGGGGTGCAGGGAGAGCGGAGCTGCTCAGA...   \n",
       "2  TGTGGAAGGCAGGCACCCCAAGCCAGGTGGGCCCCCTTCCCAAATT...   \n",
       "3  GGCTGGGAGGGGCCTGGGGGGCGGAGCGGGGCGGGAGCGGGGCGGG...   \n",
       "4  CCCAGACCCCTGTCAGGGCGCCCTCCCTGACCCGAGCCGCAGCTGC...   \n",
       "\n",
       "                                             alt_seq  \n",
       "0  AGTGCGCAGCAGGGACTGGACTGTGCACCCCACCTTTTTTTTTTTT...  \n",
       "1  CCAGCCAAGGTCTCCCAGGGGTGCAGGGAGAGCGGAGCTGCTCAGA...  \n",
       "2  TGTGGAAGGCAGGCACCCCAAGCCAGGTGGGCCCCCTTCCCAAATT...  \n",
       "3  GGCTGGGAGGGGCCTGGGGGGCGGAGCGGGGCGGGAGCGGGGCGGG...  \n",
       "4  CCCAGACCCCTGTCAGGGCGCCCTCCCTGACCCGAGCCGCAGCTGC...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pathogenic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15ef31f6-fa45-4243-a101-0d5f696956d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign rows: 180412\n",
      "Pathogenic rows: 81554\n"
     ]
    }
   ],
   "source": [
    "print(\"Benign rows:\", len(df_benign))\n",
    "print(\"Pathogenic rows:\", len(df_pathogenic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15529d-202e-4637-93e9-c6a564e95f12",
   "metadata": {},
   "source": [
    "# Save the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485eebd5-e392-4ea8-8332-09b22f525a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./clinvar_data/processed_data'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5237aef-5117-4329-8b53-3381fd5873e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved paired dataset: ./clinvar_data/processed_data/clinvar_paired_1004bp_gencode.csv\n"
     ]
    }
   ],
   "source": [
    "# Save paired dataset\n",
    "paired_csv = os.path.join(DATA_DIR, \"clinvar_paired_1004bp_gencode.csv\")\n",
    "# pd.concat([df_benign, df_pathogenic, df_uncertain], ignore_index=True).to_csv(paired_csv, index=False)\n",
    "pd.concat([df_benign, df_pathogenic], ignore_index=True).to_csv(paired_csv, index=False)\n",
    "print(f\"Saved paired dataset: {paired_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d5ead-5898-4bdc-aaf3-d45b752200b5",
   "metadata": {},
   "source": [
    "# Train/Val/Test split & Tokenizer (k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0215085d-80c0-4602-8dfe-35468a169711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_benign, df_pathogenic], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f042c1c8-bf74-4314-b1bf-3faa93350bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "benign        180412\n",
      "pathogenic     81554\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label2id = {lbl: i for i, lbl in enumerate(USE_LABELS)}\n",
    "id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "\n",
    "df_all[\"label_id\"] = df_all[\"label\"].map(label2id).astype(int)\n",
    "print(df_all[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "924656d1-487a-4b10-bbdf-ee359879250e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>ref_seq</th>\n",
       "      <th>alt_seq</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>930165</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...</td>\n",
       "      <td>CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>930204</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...</td>\n",
       "      <td>CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>930285</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>benign</td>\n",
       "      <td>CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...</td>\n",
       "      <td>CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>930314</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>benign</td>\n",
       "      <td>CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...</td>\n",
       "      <td>CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>930325</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>benign</td>\n",
       "      <td>GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...</td>\n",
       "      <td>GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom     pos ref alt   label  \\\n",
       "0     1  930165   G   A  benign   \n",
       "1     1  930204   G   A  benign   \n",
       "2     1  930285   G   A  benign   \n",
       "3     1  930314   C   T  benign   \n",
       "4     1  930325   C   T  benign   \n",
       "\n",
       "                                             ref_seq  \\\n",
       "0  CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...   \n",
       "1  CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...   \n",
       "2  CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...   \n",
       "3  CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...   \n",
       "4  GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...   \n",
       "\n",
       "                                             alt_seq  label_id  \n",
       "0  CCCCAGGCCACAGGCAGATCCCAGGAGACACGCAGGGGCCCTAAGA...         0  \n",
       "1  CCTAAGAAGGGAGCTGGGAATGAGGGGCCACACAAGCCCGGGACGG...         0  \n",
       "2  CCTGGAGTTGGCCAGGACCCTCTAGCATCCTCAAGGGCTGGGCCAA...         0  \n",
       "3  CTCAAGGGCTGGGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAG...         0  \n",
       "4  GGCCAACCAGGCTGGCGTGGGGTGGGGCAGGGGAGGGCTGAGCCAG...         0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35a272d7-0612-4d12-be57-fe78c0c04dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X',\n",
       "       'Y'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['chrom'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e4bb31-c493-4aea-96fe-a8eb14974720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>ref_seq</th>\n",
       "      <th>alt_seq</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261933</th>\n",
       "      <td>X</td>\n",
       "      <td>155260942</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>TATAAGTGAGCTCAAATACCAAGGAACAGTTGTCCTGTCTGTAGGT...</td>\n",
       "      <td>TATAAGTGAGCTCAAATACCAAGGAACAGTTGTCCTGTCTGTAGGT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261934</th>\n",
       "      <td>X</td>\n",
       "      <td>155264073</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>CATAGTAGATGATCACTGAATGTGTGCTGGTTGCAAGAAGGAATCA...</td>\n",
       "      <td>CATAGTAGATGATCACTGAATGTGTGCTGGTTGCAAGAAGGAATCA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261935</th>\n",
       "      <td>X</td>\n",
       "      <td>155264101</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>GGTTGCAAGAAGGAATCAATCGTATCTATTTCATGTTAGAACATAT...</td>\n",
       "      <td>GGTTGCAAGAAGGAATCAATCGTATCTATTTCATGTTAGAACATAT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261936</th>\n",
       "      <td>X</td>\n",
       "      <td>155264268</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>ACATAGGGACTGAGATTGATGAATTACAGATACAGAGATCAATTCC...</td>\n",
       "      <td>ACATAGGGACTGAGATTGATGAATTACAGATACAGAGATCAATTCC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261937</th>\n",
       "      <td>X</td>\n",
       "      <td>155264287</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>TGAATTACAGATACAGAGATCAATTCCAGCTAGTTTGTTAGCCACC...</td>\n",
       "      <td>TGAATTACAGATACAGAGATCAATTCCAGCTAGTTTGTTAGCCACC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrom        pos ref alt       label  \\\n",
       "261933     X  155260942   G   T  pathogenic   \n",
       "261934     X  155264073   C   T  pathogenic   \n",
       "261935     X  155264101   C   T  pathogenic   \n",
       "261936     X  155264268   G   T  pathogenic   \n",
       "261937     X  155264287   A   G  pathogenic   \n",
       "\n",
       "                                                  ref_seq  \\\n",
       "261933  TATAAGTGAGCTCAAATACCAAGGAACAGTTGTCCTGTCTGTAGGT...   \n",
       "261934  CATAGTAGATGATCACTGAATGTGTGCTGGTTGCAAGAAGGAATCA...   \n",
       "261935  GGTTGCAAGAAGGAATCAATCGTATCTATTTCATGTTAGAACATAT...   \n",
       "261936  ACATAGGGACTGAGATTGATGAATTACAGATACAGAGATCAATTCC...   \n",
       "261937  TGAATTACAGATACAGAGATCAATTCCAGCTAGTTTGTTAGCCACC...   \n",
       "\n",
       "                                                  alt_seq  label_id  \n",
       "261933  TATAAGTGAGCTCAAATACCAAGGAACAGTTGTCCTGTCTGTAGGT...         1  \n",
       "261934  CATAGTAGATGATCACTGAATGTGTGCTGGTTGCAAGAAGGAATCA...         1  \n",
       "261935  GGTTGCAAGAAGGAATCAATCGTATCTATTTCATGTTAGAACATAT...         1  \n",
       "261936  ACATAGGGACTGAGATTGATGAATTACAGATACAGAGATCAATTCC...         1  \n",
       "261937  TGAATTACAGATACAGAGATCAATTCCAGCTAGTTTGTTAGCCACC...         1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['chrom']=='X'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577c064-068b-43e2-89dd-1187dc2824f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60f8d7f8-a02e-4711-82cd-411c61f83a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subsample(df_all,SUBSET_PER_CLASS = 40_000):\n",
    "    # SUBSET_PER_CLASS = 20_000  # Just train this much sample for now\n",
    "    df_sub = (\n",
    "        df_all.groupby(\"label_id\", group_keys=False)\n",
    "              .apply(lambda x: x.sample(n=min(SUBSET_PER_CLASS, len(x)), random_state=SEED))\n",
    "              .reset_index(drop=True)\n",
    "    )\n",
    "    print(\"Using subset per class:\", SUBSET_PER_CLASS)\n",
    "    print(\"Subset counts:\", df_sub[\"label\"].value_counts())\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297b7276-36e2-48b9-9b3b-6d13d5d7f745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset per class: 40000\n",
      "Subset counts: label\n",
      "benign        40000\n",
      "pathogenic    40000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2314571/373649764.py:5: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(SUBSET_PER_CLASS, len(x)), random_state=SEED))\n"
     ]
    }
   ],
   "source": [
    "df_sub = subsample(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17b71264-89c7-401e-9f3c-a4d369c8adb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chrom\n",
       "1     21939\n",
       "2     21189\n",
       "17    16695\n",
       "X     16137\n",
       "11    14607\n",
       "3     13820\n",
       "12    13207\n",
       "7     13090\n",
       "5     12881\n",
       "16    12399\n",
       "19    12124\n",
       "6     11980\n",
       "9     11479\n",
       "15     9761\n",
       "10     9742\n",
       "8      8837\n",
       "4      8746\n",
       "14     7341\n",
       "22     5943\n",
       "13     5821\n",
       "20     5668\n",
       "18     5097\n",
       "21     3430\n",
       "Y        33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['chrom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53d3e609-a58e-41f6-9f97-6cfe3f174d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df_all, CHROM_SPLIT=True):\n",
    "    if CHROM_SPLIT:\n",
    "        ALL_CHROMS = sorted(df_all[\"chrom\"].unique().tolist())\n",
    "        print(\"Available CHROMs (VCF-style):\", ALL_CHROMS)\n",
    "    \n",
    "        CHR_TEST = {\"18\", \"21\"}   #  holdout set\n",
    "        CHR_VAL  = {\"8\"}          # small dev set\n",
    "        CHR_TRAIN = set(ALL_CHROMS) - CHR_TEST - CHR_VAL\n",
    "\n",
    "        def _by_chrom(df, chroms):\n",
    "            return df[df[\"chrom\"].isin(chroms)].reset_index(drop=True)\n",
    "\n",
    "        train_df = _by_chrom(df_all, CHR_TRAIN)\n",
    "        val_df   = _by_chrom(df_all, CHR_VAL)\n",
    "        test_df  = _by_chrom(df_all, CHR_TEST)\n",
    "\n",
    "        # sanity prints\n",
    "        for name, d in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "            uniq = sorted(d[\"chrom\"].unique().tolist())\n",
    "            counts = d[\"label\"].value_counts().to_dict()\n",
    "            print(f\"{name}: n={len(d)} | chroms={uniq} | counts={counts}\")\n",
    "\n",
    "    else:\n",
    "        # random stratified split\n",
    "        train_df, temp_df = train_test_split(\n",
    "            df_all, test_size=0.2, stratify=df_all[\"label_id\"], random_state=SEED\n",
    "        )\n",
    "        val_df, test_df = train_test_split(\n",
    "            temp_df, test_size=0.5, stratify=temp_df[\"label_id\"], random_state=SEED\n",
    "        )\n",
    "        print(\"Splits:\", len(train_df), len(val_df), len(test_df))\n",
    "    return train_df, val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5035a788-08e2-4dfc-b167-140b3cdca650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CHROMs (VCF-style): ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '3', '4', '5', '6', '7', '8', '9', 'X', 'Y']\n",
      "train: n=244602 | chroms=['1', '10', '11', '12', '13', '14', '15', '16', '17', '19', '2', '20', '22', '3', '4', '5', '6', '7', '9', 'X', 'Y'] | counts={'benign': 167808, 'pathogenic': 76794}\n",
      "val: n=8837 | chroms=['8'] | counts={'benign': 6153, 'pathogenic': 2684}\n",
      "test: n=8527 | chroms=['18', '21'] | counts={'benign': 6451, 'pathogenic': 2076}\n"
     ]
    }
   ],
   "source": [
    " train_df, val_df,test_df = prepare_data(df_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816988b-ef60-4ca1-ba57-17ce3bd38c39",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01ab67cb-2b78-4f11-bdc5-b49cc4d6cac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    kmer=KMER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a9b365b-3d32-445b-be0e-38d45af41db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmTokenizer(name_or_path='InstaDeepAI/nucleotide-transformer-500m-human-ref', vocab_size=4107, model_max_length=1000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '<unk>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59626e0c-67cd-4b5a-9c74-bec8f68214cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer test tokens: 1000\n"
     ]
    }
   ],
   "source": [
    "enc_test = tokenizer(\"ACGTN\" * 250, padding=\"max_length\", truncation=True, max_length=MAX_TOKENS)\n",
    "print(\"Tokenizer test tokens:\", len(enc_test[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4e4bf-db56-4f9a-88e9-9fe4eddfb401",
   "metadata": {},
   "source": [
    "#  Paired Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9b938c0-048e-429e-8626-bd0c33ece390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClinVarPairedDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, max_tokens: int = 1000):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        row = self.df.iloc[idx]\n",
    "        ref_seq = row[\"ref_seq\"]\n",
    "        alt_seq = row[\"alt_seq\"]\n",
    "        y = int(row[\"label_id\"])\n",
    "\n",
    "        ref_enc = self.tokenizer(\n",
    "            ref_seq,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_tokens,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        alt_enc = self.tokenizer(\n",
    "            alt_seq,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_tokens,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {\n",
    "            \"ref_input_ids\": ref_enc[\"input_ids\"].squeeze(0),\n",
    "            \"ref_attention_mask\": ref_enc[\"attention_mask\"].squeeze(0),\n",
    "            \"alt_input_ids\": alt_enc[\"input_ids\"].squeeze(0),\n",
    "            \"alt_attention_mask\": alt_enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(y, dtype=torch.long),\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9966c86-fd22-41e5-b993-20623897f660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "# collate ref/alt pairs into batches\n",
    "@dataclass\n",
    "class DataCollatorSiamese:\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch = {}\n",
    "        for key in [\"ref_input_ids\", \"ref_attention_mask\",\n",
    "                    \"alt_input_ids\", \"alt_attention_mask\",\n",
    "                    \"labels\"]:\n",
    "            batch[key] = torch.stack([f[key] for f in features])\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78683d0b-854a-44d3-9beb-8a54df23efa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = ClinVarPairedDataset(train_df, tokenizer, MAX_TOKENS)\n",
    "val_ds   = ClinVarPairedDataset(val_df, tokenizer, MAX_TOKENS)\n",
    "test_ds  = ClinVarPairedDataset(test_df, tokenizer, MAX_TOKENS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a843804d-1f18-467a-a536-a81e5711d936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeb7ca0d-5636-41b6-bf15-87c6f290202b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ex = train_ds[0]\n",
    "# for k, v in ex.items():\n",
    "#     print(k, tuple(v.shape), v.dtype)\n",
    "#     if \"input_ids\" in k:\n",
    "#         print(\" first 5 ids:\", v[:5].tolist())\n",
    "#     if \"attention_mask\" in k:\n",
    "#         print(\" sum(mask):\", int(v.sum().item()))\n",
    "# print(\"label id:\", int(ex[\"labels\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed35918-885e-4d86-b03c-e00ef8b615bc",
   "metadata": {},
   "source": [
    " # Siamese NT model (shared encoder + fusion head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98f95642-8256-41cb-bf5c-ace804cc4014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [167808  76794] -> weights: [0.7288151 1.5925853]\n"
     ]
    }
   ],
   "source": [
    "counts = train_df[\"label_id\"].value_counts().sort_index().to_numpy()\n",
    "weights = (counts.sum() / (len(counts) * counts)).astype(np.float32)\n",
    "print(\"Class counts:\", counts, \"-> weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90866d6a-a9a1-4d37-b975-c2489c7c12d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SiameseNTClassifier(nn.Module):\n",
    "    def __init__(self, base_model_name: str, num_labels: int, class_weights: Optional[np.ndarray] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "        hidden = self.encoder.config.hidden_size if hasattr(self.encoder, \"config\") else 768\n",
    "        fuse_dim = hidden * 4  # [ref, alt, alt-ref, ref*alt]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fuse_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, num_labels),\n",
    "        )\n",
    "        if class_weights is not None:\n",
    "            self.register_buffer(\"class_weights\", torch.tensor(class_weights, dtype=torch.float))\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    @staticmethod\n",
    "    def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "        summed = (last_hidden_state * mask).sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
    "        return summed / denom\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        ref_input_ids=None,\n",
    "        ref_attention_mask=None,\n",
    "        alt_input_ids=None,\n",
    "        alt_attention_mask=None,\n",
    "        labels=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \n",
    "        kwargs.pop(\"num_items_in_batch\", None)   \n",
    "        ref_out = self.encoder(input_ids=ref_input_ids, attention_mask=ref_attention_mask)  # ref\n",
    "        alt_out = self.encoder(input_ids=alt_input_ids, attention_mask=alt_attention_mask)  # alt\n",
    "\n",
    "        ref_last = ref_out.last_hidden_state\n",
    "        alt_last = alt_out.last_hidden_state\n",
    "\n",
    "        ref_repr = self.masked_mean_pool(ref_last, ref_attention_mask)\n",
    "        alt_repr = self.masked_mean_pool(alt_last, alt_attention_mask)\n",
    "\n",
    "        diff = alt_repr - ref_repr\n",
    "        prod = alt_repr * ref_repr\n",
    "        feat = torch.cat([ref_repr, alt_repr, diff, prod], dim=-1)\n",
    "\n",
    "        logits = self.classifier(feat)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if hasattr(self, \"class_weights\") and self.class_weights is not None:\n",
    "                loss_fn = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            else:\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return {\"loss\": loss, \"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d271dca7-4d8a-4859-8d86-6b99fa6f34e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-human-ref and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SiameseNTClassifier(MODEL_NAME, num_labels=2, class_weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3ca72fa-62e7-4d2c-8c5c-fde8df3ad2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNTClassifier(\n",
       "  (encoder): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(4105, 1280, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1002, 1280, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (pooler): EsmPooler(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=480, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524cae35-5d3f-4227-9780-2f6f5597c3fc",
   "metadata": {},
   "source": [
    "# Using LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b323a45-697a-4431-9c97-48eab4255215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Where to use LORA\n",
    "tm = [ \n",
    "    \"attention.self.query\",\n",
    "    \"attention.self.key\", \n",
    "    \"attention.self.value\",\n",
    "    \"attention.output.dense\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffcc72f8-3652-4961-b170-22a78bdbed26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=tm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9d3666-3685-4335-be9c-17831c603cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.encoder = get_peft_model(model.encoder, lora_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6127618-5e7f-4b4a-a0b9-4acd64d2b620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,966,080 || all params: 482,404,321 || trainable%: 0.4076\n"
     ]
    }
   ],
   "source": [
    " model.encoder.print_trainable_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8ca201e-06fa-426e-89b3-4787475def47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _summarize_params(m):\n",
    "    total = sum(p.numel() for p in m.parameters())\n",
    "    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "    non_trainable = total - trainable\n",
    "    print(f\"Total params: {total:,}\")\n",
    "    print(f\"Trainable params: {trainable:,} ({trainable/total:.2%})\")\n",
    "    print(f\"Non-trainable params: {non_trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db7ea81c-86f5-4dfe-963b-1123e9dc1a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 488,961,763\n",
      "Trainable params: 8,523,522 (1.74%)\n",
      "Non-trainable params: 480,438,241\n"
     ]
    }
   ],
   "source": [
    "_summarize_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09504368-affb-4759-883f-65d69109f0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device) #### TRANSFER TO GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae4391a7-b36f-4484-a754-412bef446ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Speed/memory-friendly flags (A100/H100 benefit; V100 ignores TF32)\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# try:\n",
    "#     torch.set_float32_matmul_precision(\"high\")\n",
    "# except Exception:\n",
    "#     pass\n",
    "\n",
    "# # Enable input grads + non-reentrant GC (better with PyTorch ≥2.0)\n",
    "# if hasattr(model, \"enable_input_require_grads\"):\n",
    "#     model.enable_input_require_grads()\n",
    "# if hasattr(model.encoder, \"gradient_checkpointing_enable\"):\n",
    "#     try:\n",
    "#         model.encoder.gradient_checkpointing_enable(\n",
    "#             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    "#         )\n",
    "#     except TypeError:\n",
    "#         model.encoder.gradient_checkpointing_enable()\n",
    "\n",
    "# # Disable KV cache during training to save memory\n",
    "# if hasattr(model.encoder, \"config\"):\n",
    "#     model.encoder.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3323ace9-91f8-4427-866b-d4bb1820e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# speed/memory-friendly flags\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  #  speedup on V100, no accuracy change\n",
    "torch.set_float32_matmul_precision(\"high\")    #  PyTorch >= 2.0\n",
    "\n",
    "#enable gradient checkpointing to trade compute for memory\n",
    "if hasattr(model.encoder, \"gradient_checkpointing_enable\"):\n",
    "    model.encoder.gradient_checkpointing_enable()  # \n",
    "# some HF models read this flag to disable key/value caching during training\n",
    "if hasattr(model.encoder, \"config\"):\n",
    "    model.encoder.config.use_cache = False  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd161c-2cbf-40fe-b556-4d6de001f104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c9cf000-ca39-4829-9cfe-710fccf3a66c",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f9176d6-9720-449b-acb8-94da63f5110b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "\n",
    "    pos_id = 1  # pathogenic\n",
    "    pos_probs = probs[:, pos_id]\n",
    "\n",
    "    out = {}\n",
    "    try:\n",
    "        out[\"auroc\"] = roc_auc_score(labels, pos_probs)\n",
    "    except ValueError:\n",
    "        out[\"auroc\"] = float(\"nan\")\n",
    "    try:\n",
    "        out[\"auprc\"] = average_precision_score(labels, pos_probs)\n",
    "    except ValueError:\n",
    "        out[\"auprc\"] = float(\"nan\")\n",
    "\n",
    "    out[\"accuracy\"]  = accuracy_score(labels, preds)\n",
    "    out[\"f1\"]        = f1_score(labels, preds, zero_division=0)\n",
    "    out[\"precision\"] = precision_score(labels, preds, zero_division=0)\n",
    "    out[\"recall\"]    = recall_score(labels, preds, zero_division=0)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086f8d7-ee2e-4424-bcbe-c14a1533c21e",
   "metadata": {},
   "source": [
    "# Training Arguments(Huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66ef5d2b-7d77-4cfe-848a-455ad43a34ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=TRAIN_EPOCHS,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,             # keep only the 2 most recent/best checkpoints\n",
    "    save_safetensors=True,          # use .safetensors when possible\n",
    "    logging_strategy=\"steps\",       # log by step\n",
    "    logging_steps=100,\n",
    "    logging_first_step=True,        # also log at step 1\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"auroc\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    #data loading optimizations\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_prefetch_factor=2,\n",
    "    \n",
    "    fp16=USE_FP16,\n",
    "    bf16=USE_BF16,\n",
    "    report_to=[\"tensorboard\"],      # write TB event files\n",
    "    logging_dir=os.path.join(OUT_DIR, \"runs\"),  # TB log dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86943f-454b-45ec-b848-a2886e52af0a",
   "metadata": {},
   "source": [
    "# Loggging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1e8ee36-b4f8-4116-bbe0-ab236dbf5ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.utils import logging as hf_logging  \n",
    "hf_logging.set_verbosity_info()                       \n",
    "hf_logging.enable_default_handler()                   \n",
    "hf_logging.enable_explicit_format()                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9930dfa1-e763-481f-a372-fc16ba2bd55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVLoggerCallback(TrainerCallback):  \n",
    "    \"\"\" Write clean CSV logs at each logging/eval step.\n",
    "    - Adds a 'split' column: 'train' or 'eval'\n",
    "    - Skips noisy keys ('epoch' duplicate, runtime counters)\n",
    "    - Rounds epoch to 6 decimals; filters NaN/Inf values\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = csv_path\n",
    "        os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "        if not os.path.exists(csv_path):\n",
    "            with open(csv_path, \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"step\", \"epoch\", \"split\", \"metric\", \"value\"])  \n",
    "\n",
    "    @staticmethod\n",
    "    def _should_skip_key(k: str) -> bool:\n",
    "        skip = {\n",
    "            \"epoch\", \"total_flos\", \"train_runtime\", \"train_samples_per_second\",\n",
    "            \"train_steps_per_second\", \"total_loss\"\n",
    "        }\n",
    "        return (k in skip) or k.startswith(\"_\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_finite_number(v) -> bool:\n",
    "        return isinstance(v, (int, float)) and math.isfinite(v)\n",
    "\n",
    "    def _write_rows(self, step: int, epoch: float | str, split: str, logs: dict):\n",
    "        with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            ep = \"\" if epoch == \"\" else round(float(epoch), 6)\n",
    "            for k, v in logs.items():\n",
    "                if self._should_skip_key(k):\n",
    "                    continue\n",
    "                if not self._is_finite_number(v):\n",
    "                    continue\n",
    "                # Strip eval_ prefix for eval metrics\n",
    "                name = k[5:] if split == \"eval\" and k.startswith(\"eval_\") else k\n",
    "                writer.writerow([step, ep, split, name, v])\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not logs:\n",
    "            return\n",
    "        step = int(state.global_step)\n",
    "        epoch = state.epoch if state.epoch is not None else \"\"\n",
    "        # Detect eval vs train by presence of any eval_* keys\n",
    "        is_eval = any(k.startswith(\"eval_\") for k in logs.keys())\n",
    "        split = \"eval\" if is_eval else \"train\"\n",
    "        self._write_rows(step, epoch, split, logs)\n",
    "\n",
    "    # Also capture metrics coming via on_evaluate explicitly (belt & suspenders)\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if not metrics:\n",
    "            return\n",
    "        step = int(state.global_step)\n",
    "        epoch = state.epoch if state.epoch is not None else \"\"\n",
    "        self._write_rows(step, epoch, \"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f216c05f-a73d-481f-b4d3-71da3718f203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./clinvar_data/clinvar_outs'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab110402-d770-4da9-956b-dc61e8e618ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_csv_path = os.path.join(OUT_DIR, \"logs\", \"train_log.csv\")  # log path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6de0cbc-bef9-41fd-8e1b-3e6a870428ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2314571/3874958522.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO|trainer.py:748] 2025-10-19 22:55:39,635 >> Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorSiamese(),   \n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=1e-4),\n",
    "        CSVLoggerCallback(log_csv_path),  #  write CSV logs\n",
    "    ],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b917dd19-fa32-4cdf-88f0-c6709b68c5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2414] 2025-10-19 22:55:40,175 >> ***** Running training *****\n",
      "[INFO|trainer.py:2415] 2025-10-19 22:55:40,176 >>   Num examples = 244,602\n",
      "[INFO|trainer.py:2416] 2025-10-19 22:55:40,177 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:2417] 2025-10-19 22:55:40,177 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:2420] 2025-10-19 22:55:40,178 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2421] 2025-10-19 22:55:40,178 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2422] 2025-10-19 22:55:40,179 >>   Total optimization steps = 38,220\n",
      "[INFO|trainer.py:2423] 2025-10-19 22:55:40,183 >>   Number of trainable parameters = 8,523,522\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38220' max='38220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38220/38220 13:57:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663900</td>\n",
       "      <td>0.687445</td>\n",
       "      <td>0.676441</td>\n",
       "      <td>0.462623</td>\n",
       "      <td>0.525744</td>\n",
       "      <td>0.513974</td>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.825633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.634084</td>\n",
       "      <td>0.709385</td>\n",
       "      <td>0.531401</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.528247</td>\n",
       "      <td>0.435730</td>\n",
       "      <td>0.670641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>0.693286</td>\n",
       "      <td>0.710216</td>\n",
       "      <td>0.523027</td>\n",
       "      <td>0.546452</td>\n",
       "      <td>0.525118</td>\n",
       "      <td>0.384990</td>\n",
       "      <td>0.825633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.661546</td>\n",
       "      <td>0.714985</td>\n",
       "      <td>0.541971</td>\n",
       "      <td>0.603599</td>\n",
       "      <td>0.531497</td>\n",
       "      <td>0.414563</td>\n",
       "      <td>0.740313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.615235</td>\n",
       "      <td>0.716591</td>\n",
       "      <td>0.542970</td>\n",
       "      <td>0.669797</td>\n",
       "      <td>0.535350</td>\n",
       "      <td>0.467464</td>\n",
       "      <td>0.626304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4307] 2025-10-20 01:37:29,416 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 01:37:29,417 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 01:37:29,418 >>   Batch size = 32\n",
      "[INFO|trainer.py:3984] 2025-10-20 01:43:05,374 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-7644\n",
      "[INFO|trainer.py:3998] 2025-10-20 01:43:05,385 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 01:43:08,421 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-7644/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 01:43:08,425 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-7644/special_tokens_map.json\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:4307] 2025-10-20 04:25:00,675 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 04:25:00,677 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 04:25:00,677 >>   Batch size = 32\n",
      "[INFO|trainer.py:3984] 2025-10-20 04:30:36,764 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-15288\n",
      "[INFO|trainer.py:3998] 2025-10-20 04:30:36,780 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 04:30:40,053 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-15288/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 04:30:40,056 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-15288/special_tokens_map.json\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:4307] 2025-10-20 07:12:35,251 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 07:12:35,252 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 07:12:35,252 >>   Batch size = 32\n",
      "[INFO|trainer.py:3984] 2025-10-20 07:18:11,160 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-22932\n",
      "[INFO|trainer.py:3998] 2025-10-20 07:18:11,174 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 07:18:14,520 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-22932/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 07:18:14,523 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-22932/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-10-20 07:18:14,783 >> Deleting older checkpoint [clinvar_data/clinvar_outs/checkpoint-7644] due to args.save_total_limit\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:4307] 2025-10-20 10:00:05,838 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 10:00:05,839 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 10:00:05,839 >>   Batch size = 32\n",
      "[INFO|trainer.py:3984] 2025-10-20 10:05:41,775 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-30576\n",
      "[INFO|trainer.py:3998] 2025-10-20 10:05:41,789 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 10:05:44,979 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-30576/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 10:05:44,982 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-30576/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-10-20 10:05:45,274 >> Deleting older checkpoint [clinvar_data/clinvar_outs/checkpoint-15288] due to args.save_total_limit\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:4307] 2025-10-20 12:47:40,020 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 12:47:40,022 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 12:47:40,023 >>   Batch size = 32\n",
      "[INFO|trainer.py:3984] 2025-10-20 12:53:16,099 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-38220\n",
      "[INFO|trainer.py:3998] 2025-10-20 12:53:16,114 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 12:53:19,423 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 12:53:19,427 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/special_tokens_map.json\n",
      "[INFO|trainer.py:4083] 2025-10-20 12:53:19,551 >> Deleting older checkpoint [clinvar_data/clinvar_outs/checkpoint-22932] due to args.save_total_limit\n",
      "[INFO|trainer.py:2681] 2025-10-20 12:53:19,564 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2910] 2025-10-20 12:53:19,565 >> Loading best model from ./clinvar_data/clinvar_outs/checkpoint-38220 (score: 0.716590576658836).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=38220, training_loss=0.6425233478760731, metrics={'train_runtime': 50260.4506, 'train_samples_per_second': 24.333, 'train_steps_per_second': 0.76, 'total_flos': 0.0, 'train_loss': 0.6425233478760731, 'epoch': 5.0})\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545dc417-a94c-41de-85c8-8687cd1e177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2414] 2025-10-20 14:53:48,347 >> ***** Running training *****\n",
      "[INFO|trainer.py:2415] 2025-10-20 14:53:48,348 >>   Num examples = 244,602\n",
      "[INFO|trainer.py:2416] 2025-10-20 14:53:48,349 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:2417] 2025-10-20 14:53:48,350 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:2420] 2025-10-20 14:53:48,351 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2421] 2025-10-20 14:53:48,351 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2422] 2025-10-20 14:53:48,352 >>   Total optimization steps = 38,220\n",
      "[INFO|trainer.py:2423] 2025-10-20 14:53:48,357 >>   Number of trainable parameters = 8,523,522\n",
      "/home/nkhat001/miniconda3/envs/gpuenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7103' max='38220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7103/38220 2:30:09 < 10:57:59, 0.79 it/s, Epoch 0.93/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result2 = trainer.train()\n",
    "print(train_result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011b7a1-7437-4c7c-b0e4-f1efd485e69d",
   "metadata": {},
   "source": [
    "# Evaluate and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd6b6e3c-15c7-4f81-b86f-56ad891bf5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4307] 2025-10-20 12:53:20,664 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 12:53:20,665 >>   Num examples = 8837\n",
      "[INFO|trainer.py:4312] 2025-10-20 12:53:20,666 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='277' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [277/277 10:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4307] 2025-10-20 12:58:56,735 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4309] 2025-10-20 12:58:56,737 >>   Num examples = 8527\n",
      "[INFO|trainer.py:4312] 2025-10-20 12:58:56,737 >>   Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'eval_loss': 0.6152347326278687, 'eval_auroc': 0.716590576658836, 'eval_auprc': 0.5429701473194328, 'eval_accuracy': 0.6697974425710083, 'eval_f1': 0.5353503184713376, 'eval_precision': 0.4674638487208009, 'eval_recall': 0.6263040238450075, 'eval_runtime': 336.0447, 'eval_samples_per_second': 26.297, 'eval_steps_per_second': 0.824, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3984] 2025-10-20 13:04:21,052 >> Saving model checkpoint to ./clinvar_data/clinvar_outs/checkpoint-38220\n",
      "[INFO|trainer.py:3998] 2025-10-20 13:04:21,066 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: {'eval_loss': 0.6093655824661255, 'eval_auroc': 0.69308297558981, 'eval_auprc': 0.4528098351004526, 'eval_accuracy': 0.6735076814823502, 'eval_f1': 0.4583657587548638, 'eval_precision': 0.38446475195822455, 'eval_recall': 0.5674373795761078, 'eval_runtime': 324.302, 'eval_samples_per_second': 26.293, 'eval_steps_per_second': 0.823, 'epoch': 5.0}\n",
      " Best checkpoint: ./clinvar_data/clinvar_outs/checkpoint-38220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 13:04:25,617 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 13:04:25,621 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2510] 2025-10-20 13:04:25,632 >> tokenizer config file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2025-10-20 13:04:25,635 >> Special tokens file saved in ./clinvar_data/clinvar_outs/checkpoint-38220/special_tokens_map.json\n",
      "[INFO|configuration_utils.py:693] 2025-10-20 13:04:25,824 >> loading configuration file config.json from cache at /home/nkhat001/.cache/huggingface/hub/models--InstaDeepAI--nucleotide-transformer-500m-human-ref/snapshots/f87b5d7233295242e79c951873d290f4cf992045/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-10-20 13:04:25,827 >> Model config EsmConfig {\n",
      "  \"architectures\": [\n",
      "    \"EsmForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"emb_layer_norm_before\": false,\n",
      "  \"esmfold_config\": null,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"is_folding_model\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token_id\": 2,\n",
      "  \"max_position_embeddings\": 1002,\n",
      "  \"model_type\": \"esm\",\n",
      "  \"num_attention_heads\": 20,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"token_dropout\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_list\": null,\n",
      "  \"vocab_size\": 4105\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved LoRA adapter to: ./clinvar_data/clinvar_outs/checkpoint-38220/lora_adapter\n",
      " Best model & tokenizer saved to: ./clinvar_data/clinvar_outs/checkpoint-38220\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation:\", trainer.evaluate(eval_dataset=val_ds))\n",
    "print(\"Test:\", trainer.evaluate(eval_dataset=test_ds))\n",
    "\n",
    "#  determine best checkpoint dir (fallback to OUT_DIR if none)\n",
    "best_dir = trainer.state.best_model_checkpoint or OUT_DIR  # \n",
    "print(f\" Best checkpoint: {best_dir}\")  #\n",
    "\n",
    "# save full trainer model snapshot into best_dir (will include classifier; PEFT may store adapters)\n",
    "trainer.save_model(best_dir)  \n",
    "\n",
    "#  save tokenizer alongside best checkpoint\n",
    "tokenizer.save_pretrained(best_dir)  \n",
    "\n",
    "# if using PEFT/LoRA, also save adapters explicitly\n",
    "try:\n",
    "    adapter_dir = os.path.join(best_dir, \"lora_adapter\")\n",
    "    os.makedirs(adapter_dir, exist_ok=True)\n",
    "    model.encoder.save_pretrained(adapter_dir)  # PEFT: writes adapter config + weights\n",
    "    # Save classifier head separately for redundancy\n",
    "    torch.save(model.classifier.state_dict(), os.path.join(best_dir, \"classifier.pt\"))\n",
    "    print(f\" Saved LoRA adapter to: {adapter_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\" PEFT adapter save skipped/failed: {e}\")\n",
    "\n",
    "print(f\" Best model & tokenizer saved to: {best_dir}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e28b4-46eb-40cb-b734-4450385a02b2",
   "metadata": {},
   "source": [
    "# Reload helper (Best checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cc0236f-7a91-4e26-ab8f-187859fec047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_best_siamese(checkpoint_dir: str) -> SiameseNTClassifier:\n",
    "    base = SiameseNTClassifier(MODEL_NAME, num_labels=2, class_weights=None)\n",
    "    # Load LoRA adapter if present\n",
    "    adapter_path = os.path.join(checkpoint_dir, \"lora_adapter\")\n",
    "    if os.path.isdir(adapter_path):\n",
    "        from peft import PeftModel\n",
    "        base.encoder = PeftModel.from_pretrained(base.encoder, adapter_path)\n",
    "    # Load the whole-state dict fallback if available (from trainer.save_model)\n",
    "    state_dict_path_bin = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
    "    state_dict_path_sft = os.path.join(checkpoint_dir, \"model.safetensors\")\n",
    "    if os.path.exists(state_dict_path_sft):\n",
    "        from safetensors.torch import load_file\n",
    "        sd = load_file(state_dict_path_sft)\n",
    "        base.load_state_dict(sd, strict=False)\n",
    "    elif os.path.exists(state_dict_path_bin):\n",
    "        sd = torch.load(state_dict_path_bin, map_location=\"cpu\")\n",
    "        base.load_state_dict(sd, strict=False)\n",
    "    else:\n",
    "        # load classifier if we saved it\n",
    "        clf_path = os.path.join(checkpoint_dir, \"classifier.pt\")\n",
    "        if os.path.exists(clf_path):\n",
    "            base.classifier.load_state_dict(torch.load(clf_path, map_location=\"cpu\"))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20882a15-4922-4d59-b262-006facba32d6",
   "metadata": {},
   "source": [
    "# Inference helper (paired ref/alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ceeb240-bbad-408a-8cdd-1a921c612b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_ref_alt(ref_seqs: List[str], alt_seqs: List[str]) -> List[Dict[str, float]]:\n",
    "    assert len(ref_seqs) == len(alt_seqs)\n",
    "    ref_enc = tokenizer(ref_seqs, padding=True, truncation=True, max_length=MAX_TOKENS, return_tensors=\"pt\")\n",
    "    alt_enc = tokenizer(alt_seqs, padding=True, truncation=True, max_length=MAX_TOKENS, return_tensors=\"pt\")\n",
    "    ref_enc = {k: v.to(device) for k, v in ref_enc.items()}\n",
    "    alt_enc = {k: v.to(device) for k, v in alt_enc.items()}\n",
    "    out = model(\n",
    "        ref_input_ids=ref_enc[\"input_ids\"],\n",
    "        ref_attention_mask=ref_enc[\"attention_mask\"],\n",
    "        alt_input_ids=alt_enc[\"input_ids\"],\n",
    "        alt_attention_mask=alt_enc[\"attention_mask\"],\n",
    "    )\n",
    "    probs = torch.softmax(out[\"logits\"], dim=-1).cpu().numpy()\n",
    "    return [{id2label[i]: float(p) for i, p in enumerate(row)} for row in probs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6ee788f-f15b-4e15-b74c-e893e2507967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = predict_ref_alt(test_df[\"ref_seq\"].head(10).tolist(), test_df[\"alt_seq\"].head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "705bdf09-bbd4-41a0-9bbc-5cef47229565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'benign': 0.41584742069244385, 'pathogenic': 0.5841525197029114},\n",
       " {'benign': 0.5528414845466614, 'pathogenic': 0.4471585154533386},\n",
       " {'benign': 0.5188356637954712, 'pathogenic': 0.4811643064022064},\n",
       " {'benign': 0.6111499667167664, 'pathogenic': 0.38885006308555603},\n",
       " {'benign': 0.4409506916999817, 'pathogenic': 0.5590493679046631},\n",
       " {'benign': 0.6813028454780579, 'pathogenic': 0.31869715452194214},\n",
       " {'benign': 0.6361271142959595, 'pathogenic': 0.36387285590171814},\n",
       " {'benign': 0.35309356451034546, 'pathogenic': 0.6469064354896545},\n",
       " {'benign': 0.6740504503250122, 'pathogenic': 0.3259495198726654},\n",
       " {'benign': 0.45314082503318787, 'pathogenic': 0.5468591451644897}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520930f-8153-40c0-9b0c-fb3f639d605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "nisgpuenv",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python3.10(gpujax-env)",
   "language": "python",
   "name": "gpujax-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
